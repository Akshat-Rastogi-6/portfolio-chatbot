# Portfolio Chatbot

This project is a Flask-based chatbot designed to answer questions based on a resume. It uses Google's Generative AI (Gemini) for natural language understanding and response generation, and FAISS for efficient similarity search on resume content.

## Features

- **Resume-based Q&A:** Answers questions based on the content of a processed resume.
- **Natural Language Understanding:** Leverages Google's Gemini model to understand user queries.
- **Efficient Search:** Uses FAISS for quick retrieval of relevant resume sections.
- **Flask API:** Provides a simple API endpoint for chat interactions.

## Technologies Used

- **Python:** Core programming language.
- **Flask:** Web framework for the API.
- **Flask-CORS:** Handles Cross-Origin Resource Sharing.
- **Google Generative AI (Gemini):** For language modeling and text embedding.
- **FAISS:** For similarity search.
- **PyPDF2:** For reading PDF resume files (though not directly used in `app.py`, it's implied for preprocessing).
- **NumPy:** For numerical operations.
- **Torch:** For tensor operations.
- **Waitress:** Production WSGI server.
- **python-dotenv:** For managing environment variables.

## Project Structure

```
portfolio-chatbot/
├── .gitignore          # Specifies intentionally untracked files that Git should ignore
├── app.py              # Main Flask application file
├── docs/
│   ├── chunked_data.pkl  # Pickled preprocessed resume chunks
│   └── resume_index.faiss # FAISS index for resume embeddings
├── readme.md           # This file
├── requirements.txt    # Python dependencies
└── .env                # Environment variables (e.g., GEMINI_API_KEY) - Not committed
```

## Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd portfolio-chatbot
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up environment variables:**
    Create a `.env` file in the root directory and add your Google Gemini API key:
    ```env
    GEMINI_API_KEY=your_gemini_api_key_here
    ```

5.  **Prepare resume data:**
    - You'll need to have `docs/chunked_data.pkl` and `docs/resume_index.faiss` files. These are generated by a preprocessing script (not included in `app.py` but essential for the application to work). This script would typically:
        - Read a resume (e.g., PDF).
        - Chunk the text.
        - Generate embeddings for each chunk using `models/text-embedding-004`.
        - Create a FAISS index from these embeddings.
        - Save the chunks and the FAISS index.

## Usage

1.  **Run the Flask application:**
    ```bash
    python app.py
    ```
    The application will be served by Waitress, typically on `http://0.0.0.0:5000`.

2.  **Interact with the chatbot:**
    Send a POST request to the `/chat` endpoint with a JSON payload containing the user's message.

    Example using `curl`:
    ```bash
    curl -X POST -H "Content-Type: application/json" -d '{"message": "What are your skills?"}' http://localhost:5000/chat
    ```

## API Endpoints

-   **`GET /`**
    -   Description: A simple health check endpoint.
    -   Response:
        ```json
        "App is running!"
        ```
        Status Code: `200 OK`

-   **`POST /chat`**
    -   Description: Main endpoint for sending messages to the chatbot.
    -   Request Body (JSON):
        ```json
        {
            "message": "Your question about the resume"
        }
        ```
    -   Response Body (JSON):
        ```json
        {
            "response": "Chatbot's answer"
        }
        ```
    -   Error Response (if message is missing):
        ```json
        {
            "response": "Sorry, I didn't understand your message."
        }
        ```

## Key Files

-   **`app.py`**:
    -   Initializes the Flask application.
    -   Configures CORS and loads environment variables.
    -   Defines the `/` and `/chat` API endpoints.
    -   `process_resume_and_query(query)` function:
        -   Loads preprocessed resume chunks (`chunked_data.pkl`) and the FAISS index (`resume_index.faiss`).
        -   Generates an embedding for the user's query using Google's `text-embedding-004` model.
        -   Searches the FAISS index for the most relevant resume chunks.
        -   Constructs a prompt with context (retrieved chunks) and the user's query.
        -   Uses the `gemini-1.5-flash` model to generate a response.
-   **`requirements.txt`**: Lists all Python packages required to run the project. Install them using `pip install -r requirements.txt`.
-   **`.gitignore`**: Specifies files and directories that Git should ignore (e.g., `.env`, `backend/`, `__pycache__/`). This helps keep the repository clean and avoids committing sensitive information or generated files.
-   **`docs/chunked_data.pkl`**: A pickle file containing the preprocessed, chunked text data from the resume.
-   **`docs/resume_index.faiss`**: The FAISS index file created from the embeddings of the resume chunks, enabling fast similarity searches.

## To-Do / Improvements


-   [ ] Implement more robust error handling.
-   [ ] Add unit and integration tests.
-   [ ] Create a simple frontend for easier interaction.
-   [ ] Allow dynamic resume uploads and processing.